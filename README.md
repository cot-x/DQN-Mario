# DQN-Mario
Training Mario via DQN and A2C. And a little test.

## python Mario/DQN.py --help
```
usage: DQN.py [-h] [--env_name ENV_NAME] [--weight_dir WEIGHT_DIR] [--lr LR] [--gamma GAMMA] [--batch_size BATCH_SIZE]
              [--mem_capacity MEM_CAPACITY] [--num_updates NUM_UPDATES] [--savemovie] [--cpu]

options:
  -h, --help            show this help message and exit
  --env_name ENV_NAME
  --weight_dir WEIGHT_DIR
  --lr LR
  --gamma GAMMA
  --batch_size BATCH_SIZE
  --mem_capacity MEM_CAPACITY
  --num_updates NUM_UPDATES
  --savemovie
  --cpu
```

## python Mario/A2C.py --help
```
usage: A2C.py [-h] [--env_name ENV_NAME] [--weight_dir WEIGHT_DIR] [--lr LR] [--mem_capacity MEM_CAPACITY] [--batch_size BATCH_SIZE]
              [--num_updates NUM_UPDATES] [--cpu] [--savemovie]

options:
  -h, --help            show this help message and exit
  --env_name ENV_NAME
  --weight_dir WEIGHT_DIR
  --lr LR
  --mem_capacity MEM_CAPACITY
  --batch_size BATCH_SIZE
  --num_updates NUM_UPDATES
  --cpu
  --savemovie
```
